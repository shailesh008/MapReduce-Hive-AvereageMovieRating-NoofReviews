{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww28600\viewh18000\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\qc\partightenfactor0

\fs28 \cf0 Queries/Commands Executed on Hive & Map Reduce
\fs24 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\qc\partightenfactor0

\fs28 \cf0 :Hive:
\fs24 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul \ulc0 For Small DataSet:\ulnone \
\
1)	\ul Reviews Table:\ulnone \
\
-> Table Creation:\
- 
\b0 CREATE TABLE reviews ( userId INT, movieId INT, rating DOUBLE, timestamp BIGINT) row format delimited fields terminated BY ',' tblproperties("skip.header.line.count"="1");
\b \
-> Data Entry:\
-
\b0  load data local inpath \'93dataset/reviews/reviews.csv" overwrite into table imdb_bigdata15.reviews;
\b \
\
\
2)	\ul Movies Table:\ulnone \
-> Table Creation:\
- 
\b0 create table movies(moviesId INT, title STRING, genres STRING) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' tblproperties("skip.header.line.count"="1");
\b \
-> Data Entry:\
- l
\b0 oad data local inpath "dataset/movies/movies.csv" overwrite into table imdb_bigdata15.movies;
\b \
\
\
\ul Queries Executed on Hive:\ulnone \
\
-> For Part-1:-\
\

\b0 select count(movieid) as noOfReviews, movies.title from reviews,movies where movies.moviesid = reviews.movieid group by movies.moviesid,movies.title order by noOfReviews asc;\

\b \
-> For Part-2:-\
\

\b0 select movies.title, avg(rating) as AvgMovieRat, count(movieid) as NoOfReviews from reviews,movies where movies.moviesid = reviews.movieid group by movies.title having AvgMovieRat>4 and NoOfReviews>10 order by AvgMovieRat;\

\b \
\ul For Large Dataset:\ulnone \
\
1)	\ul Reviews Table:\ulnone \
\
-> Table Creation:\

\b0 - CREATE TABLE reviews_large ( userId INT, movieId INT, rating DOUBLE, timestamp BIGINT) row format delimited fields terminated BY ',' tblproperties("skip.header.line.count"="1");\

\b -> Data Entry:\

\b0 - load data local inpath \'93dataset_large/reviews/reviews_large.csv" overwrite into table imdb_bigdata15.reviews_large;\

\b \
\
2)	\ul Movies Table:\ulnone \
-> Table Creation:\

\b0 - create table movies_large(moviesId INT, title STRING, genres STRING) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' tblproperties("skip.header.line.count"="1");\

\b -> Data Entry:\

\b0 - load data local inpath "dataset_large/movies/movies_large.csv" overwrite into table imdb_bigdata15.movies_large;\

\b \
\ul Queries Executed on Hive:\ulnone \
\
-> For Part-1:-\
\

\b0 select count(movieid) as noOfReviews, movies_large.title from reviews_large,movies_large where movies_large.moviesid = reviews_large.movieid group by movies_large.moviesid,movies_large.title order by noOfReviews asc;\

\b \
-> For Part-2:\'97\'97\
\

\b0 select movies_large.title, avg(rating) as AvgMovieRat, count(movieid) as NoOfReviews from reviews_large,movies_large where movies_large.moviesid = reviews_large.movieid group by movies_large.title having AvgMovieRat>4 and NoOfReviews>10 order by AvgMovieRat;\

\b \
\
\
\
\
\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\qc\partightenfactor0

\fs28 \cf0 :MapReduce:
\fs24 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \ul For Small DataSet:\
\ulnone \
-> Part-1:-\

\b0 hadoop jar MapReduceAssignment1.jar -Dmapreduce.job.reduces=1 -Dmapreduce.input.fileinputformat.split.maxsize=16777216 ./dataset/movies/movies.csv  ./dataset/reviews/reviews.csv ./MapReduceAssignments_Output/dataset_small/MapReduceAssignment-1_Output FinalDriver\

\b \
\
-> Part:-2:\

\b0 hadoop jar MapReduceAssignment2.jar -Dmapreduce.job.reduces=1 -Dmapreduce.input.fileinputformat.split.maxsize=16777216 ./dataset/movies/movies.csv  ./dataset/reviews/reviews.csv ./MapReduceAssignments_Output/dataset_small/MapReduceAssignment-2_Output FinalDriver\

\b \
\ul For Large DataSet:-\
\ulnone \
-> Part-1:-\

\b0 hadoop jar MapReduceAssignment1.jar -Dmapreduce.job.reduces=1 -Dmapreduce.input.fileinputformat.split.maxsize=16777216 ./dataset_large/movies/movies_large.csv  ./dataset_large/reviews/reviews_large.csv ./MapReduceAssignments_Output/dataset_large/MapReduceAssignment-1_Output FinalDriver\

\b \
-> Part-2:-\

\b0 hadoop jar MapReduceAssignment2.jar -Dmapreduce.job.reduces=1 -Dmapreduce.input.fileinputformat.split.maxsize=16777216 ./dataset_large/movies/movies_large.csv  ./dataset_large/reviews/reviews_large.csv ./MapReduceAssignments_Output/dataset_large/MapReduceAssignment-2_Output FinalDriver\

\b \
\
\
\
\
\
}